---
title: "p8105_hw3_wz2506"
author: "Weiran Zhang"
date: "10/11/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggridges)
library(viridis)
library(forcats)
```


##Problem 1

```{r}
library(p8105.datasets)
data("instacart") ##Load data instacart

```

```{r}
##How many aisle in total
max(pull(instacart, aisle_id))
min(pull(instacart, aisle_id))

##wrangle the table to aisle_id and number of items ordered from each aisle
instacart = instacart %>%
  group_by(aisle_id) %>%
  summarize(n = n())


```
`Range of aisle_id is from 1 to 134, so there are 134 aisles in total.`


```{r}
##dataset of aisle_id and number of items ordered from the aisles over 10000 to check for the aisle with the most items ordered from
instacart %>%
  mutate(
    large = case_when(
      n > 10000 ~ "large",
      n <= 10000 ~ "not_large",
      TRUE     ~ ""
    )) %>%
  filter(large == "large") %>%
  group_by(aisle_id, large)

##plot of number of items ordered from each aisle for items number over 10000
instacart %>%
  mutate(
    large = case_when(
      n > 10000 ~ "large",
      n <= 10000 ~ "not_large",
      TRUE     ~ ""
    )) %>%
  filter(large == "large") %>%
  group_by(aisle_id, large) %>%
  ggplot(aes(x = aisle_id, y = n)) +
  geom_point()

```

`From the dataset of aisle_id and number of items over 10000, we can see that the aisle with aisle_id = 83 is the aisle with most items oredered from.`

```{r}
##Table of three most popular items in the three specific aisles
library(p8105.datasets)
data("instacart")
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(n = n()) %>%
  filter(min_rank(desc(n)) < 4 )%>%
  knitr::kable(digits = 1)

```

`So the three most popular items in aisle of baking ingredient are cane sugar(336), light brown sugar(499) and pure baking soda(387), in aisle of dog food care are organix chicken & brown rice recipe(28), small dog biscuits and snack sticks chicken(26) & rice recipe dog(30), in aisle packaged vegetables fruits are organic baby spinach(9784), organic blueberries(4966) and organic raspberries(5546). `

```{r}
##Table of mean hour of day
library(p8105.datasets)
data("instacart")
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  mutate(order_dow = replace(order_dow, order_dow == '0', 'Sunday'),
         order_dow = replace(order_dow, order_dow == '1', 'Monday'),
         order_dow = replace(order_dow, order_dow == '2', 'Tuesday'),
         order_dow = replace(order_dow, order_dow == '3', 'Wednesday'),
         order_dow = replace(order_dow, order_dow == '4', 'Thursday'),
         order_dow = replace(order_dow, order_dow == '5', 'Friday'),
         order_dow = replace(order_dow, order_dow == '6', 'Saturnday'),
  ) %>%
  group_by(product_name, order_dow) %>%
  summarize(meanhour = mean(order_hour_of_day)) %>%
  pivot_wider(
    id_cols = c(product_name, order_dow, meanhour),
    names_from = order_dow,
    values_from = meanhour) %>%
  knitr::kable(digits = 1)

```

`So from the table of mean hour of order, we can see that Wednesday it tooks longer to order for both Coffee ice Cream and Pink Lady Apples. But the mean hours are all about between 11-15 hours. `

`There are 15 variables in this instacart dataset and 1384617 observations in total. Key variables including aisle wich represents the products types aisle contains, aisle_id which are the id number of aisle, product_name which is the product name, order_dow whic are the day of a week items ordered, order_hour_of_day which are average number of hours ordered in a day.`

##Problem 2

```{r}
##Load BRFSS dataset
library(p8105.datasets)
data("brfss_smart2010")

```

```{r}
##Data cleaning following the instructions
tidy_data = brfss_smart2010 %>%
  filter(Topic == "Overall Health", 
         Response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% ##focus only on "Overall Health" topic and the five response types
  select(state = Locationabbr, location = Locationdesc, everything()) %>% ##change to reasonable names
  mutate(Response = as.factor(Response)) %>% ##taking the response as factor variable
  mutate(Response = forcats::fct_relevel(Response, c("Excellent","Very Good","Good","Fair","Poor"))) %>%
  arrange(Response)
```

```{r}
##states that observed at 7 or more locations in year 2002
brfss_smart2010 %>%
  filter(Topic == "Overall Health", 
         Response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"), 
         Year == "2002") %>%
  group_by(Locationdesc) %>%
  summarize(n = n()) %>%
  separate(Locationdesc, c("state","county"), sep = "-") %>%
  group_by(state) %>%
  summarize(n = n()) %>%
  mutate(
    observed = case_when(
      n >= 7 ~ "observed",
      n < 7 ~ "not_observed",
      TRUE     ~ ""
    )) %>%
  filter(observed == "observed") %>%
  group_by(observed)

##states that observed at 7 or more locations in year 2010
brfss_smart2010 %>%
  filter(Topic == "Overall Health", 
         Response %in% c("Excellent", "Very good", "Good", "Fair", "Poor"), 
         Year == "2010") %>%
  group_by(Locationdesc) %>%
  summarize(n = n()) %>%
  separate(Locationdesc, c("state","county"), sep = "-") %>%
  group_by(state) %>%
  summarize(n = n()) %>%
  mutate(
    observed = case_when(
      n >= 7 ~ "observed",
      n < 7 ~ "not_observed",
      TRUE     ~ ""
    )) %>%
  filter(observed == "observed") %>%
  group_by(observed)

```

`There are 6 states that are observed for more than 7 times in 2002, and 14 states observed for more than 7 times in 2010.`

```{r}
##“spaghetti” plot
brfss_smart2010 %>%
  select(Year, Response, Locationabbr, Data_value) %>%
  filter(Response == "Excellent") %>%
  group_by(Locationabbr, Year) %>%
  summarize(mean_data = mean(Data_value)) %>%
  ggplot(aes(x = Year, y = mean_data, color = Locationabbr)) +
  geom_point() + geom_line() 

```

```{r}
##Two-panel plots showing distribution of data_value
tidy_data %>%
  filter(Year %in% c(2006, 2010), 
         state == "NY") %>%
  ggplot(aes(x = Response, y = Data_value)) +
  geom_boxplot() + 
  facet_grid(~Year) +
  viridis::scale_fill_viridis(discrete = TRUE)

```

##Problem 3

```{r}
##Load and tidy accel dataset
accel = read_csv(file = "/Users/weiranzhang/p8105_hw3_wz2506/accel_data.csv") %>%
  mutate(weekday_vs_weekend =
           ifelse(day %in% c("Saturnday","Sunday"), "Weekend", "Weekday"))
  
```

`The first three variables are week number(week), day number(day_id) and day of a week(day) with the additional variable weekday vs. weekend shows whether it is a weekday ot weekend. There are 1440 columns of activity data value recording by each minute in a day. And there are total 35 observations representing 35 days of observation period.`

```{r}
##Total activity variable aggregate across minute
sum = accel %>%
  mutate(Total = rowSums(accel[,4:1443])) %>%
  select(week, day_id, day, Total)

```

`There is no apperant trands in the total number of activity data value by day from those 35 days.`

```{r}
##single-panel plot of 24-hour activity vs. time
databyhour = accel %>%
  pivot_longer(
    activity.1:activity.1440,
    names_to = "minute",
    names_prefix = "activity.",
    values_to = "activity"
  ) %>%
  mutate(minute = as.numeric(minute),
         hour = minute %/% 60) %>%
  group_by(day, hour, week) %>%
  summarize(activitycounts = sum(activity)) 

week1 = databyhour %>%
  filter(week == 1)

week2 = databyhour %>%
  filter(week == 2)

week3 = databyhour %>%
  filter(week == 3)

week4 = databyhour %>%
  filter(week == 4)

week5 = databyhour %>%
  filter(week == 5)

  ggplot() +
  geom_line(week1, mapping = aes(x = hour, y = activitycounts, color = day)) + geom_line(week2, mapping = aes(x = hour, y = activitycounts, color = day)) + geom_line(week3, mapping = aes(x = hour, y = activitycounts, color = day)) + geom_line(week4, mapping = aes(x = hour, y = activitycounts, color = day)) + geom_line(week5, mapping = aes(x = hour, y = activitycounts, color = day)) 

```

`There are four obvious peaks in the plot which we can see are around hour 5, 10, 15 and 20, and the max happens at around hour 20 which we can see by color is a Monday. And for three other smaller peaks are all happens at different day of a week. But overall, there is no obvious pattern for the activity data value we can see from this plot. And the most concentrated part of activity values are between 1500-4500.`




